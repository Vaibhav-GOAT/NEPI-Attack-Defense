# Narrative-Embedded Prompt Injection (NEPI): Attack and Defense Framework

This repository contains the official implementation of **Narrative-Embedded Prompt Injection (NEPI)**, a novel prompt injection attack paradigm where adversarial intent is embedded inside **fictional narratives, role-play prompts, dialogue structures, and coherent story flows**. Unlike traditional jailbreak attacks that rely on explicit override instructions, NEPI leverages semantic camouflage and narrative consistency to bypass common prompt filtering and boundary enforcement defenses.

In addition to introducing and evaluating NEPI, this repository provides a **hybrid defense pipeline** that mitigates narrative-based prompt injection using a combination of **prompt classification, suspicious prompt revision, and output validation**.

This repository is created as part of the thesis/research work:

> **Narrative-Embedded Prompt Injection in Large Language Models: Attack Characterization and Defense Strategies**  
> Vaibhav Pawar, Dr. Urvashi  
> Dr. B. R. Ambedkar NIT Jalandhar

---

## âš ï¸ Safety and Responsible Use

This repository is intended strictly for **academic research**, **defensive security evaluation**, and **authorized red-teaming**.

- Do not use this code to harm systems, users, or services.
- Do not attempt attacks on deployed systems without explicit permission.
- Prompts provided in this repository are intended for controlled evaluation only.

See: [`docs/SAFETY.md`](docs/SAFETY.md)

---

## ğŸ“Œ Key Contributions

This repository provides:

- Implementation of **NEPI attack generation**
- Taxonomy of narrative injection variants:
  - Role-based Persona Hijacking
  - Dialogue-based Conversational Drift
  - Monologue-based Internal Reasoning Abuse
  - Mixed-Intent / Heterogeneous Injection
- Baseline jailbreak attack implementations
- Evaluation scripts for Attack Success Rate (ASR)
- Hybrid defense pipeline:
  - 3-class prompt classifier (**Safe / Suspicious / Malicious**)
  - Suspicious prompt revision module
  - Post-generation output validation and filtering
- Plot generation scripts for:
  - Heatmaps
  - Bar charts
  - ROC and Precision-Recall curves
  - Security vs usability tradeoff plots

---

## ğŸ§ª Models Evaluated

The experimental framework supports evaluation on HuggingFace-hosted instruction-tuned models, including:

- Meta LLaMA
- Mistral
- Vicuna
- Falcon
- Gemma

The evaluation is designed to measure **cross-model transferability** of NEPI attacks.

---

## ğŸ“‚ Repository Structure

NEPI-Attack-Defense/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ CITATION.cff
â”‚
â”œâ”€â”€ docs/
â”‚ â”œâ”€â”€ SAFETY.md
â”‚ â”œâ”€â”€ THREAT_MODEL.md
â”‚ â””â”€â”€ REPRODUCIBILITY.md
â”‚
â”œâ”€â”€ dataset/
â”‚ â”œâ”€â”€ README.md
â”‚ â”œâ”€â”€ nepi_dataset_sample.csv
â”‚ â””â”€â”€ schema.json
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ attack/
â”‚ â”‚ â”œâ”€â”€ nepi_generator.py
â”‚ â”‚ â””â”€â”€ baseline_attacks.py
â”‚ â”‚
â”‚ â”œâ”€â”€ defense/
â”‚ â”‚ â”œâ”€â”€ pipeline.py
â”‚ â”‚ â””â”€â”€ output_validator.py
â”‚ â”‚
â”‚ â””â”€â”€ evaluation/
â”‚ â””â”€â”€ metrics.py
â”‚
â”œâ”€â”€ scripts/
â”‚ â”œâ”€â”€ run_attack_eval.py
â”‚ â”œâ”€â”€ run_defense_eval.py
â”‚ â””â”€â”€ generate_figures.py
â”‚
â””â”€â”€ notebooks/
â”œâ”€â”€ NEPI_Attack_Evaluation.ipynb
â””â”€â”€ NEPI_Defense_Evaluation.ipynb


---

## ğŸ“Š Dataset

This repository contains only a **small sample dataset** under `dataset/` for demonstration and schema reference.  
The complete dataset (3000+ prompts) will be released separately on HuggingFace.

Planned HuggingFace dataset link:

https://huggingface.co/datasets/Vaibhav-GOAT/nepi-prompts-dataset


---

## ğŸš€ Quick Start (Google Colab Recommended)

The easiest way to reproduce experiments is using Google Colab.

Colab link:

https://colab.research.google.com/drive/1zwlhjOY_ra3-USTzXeGt4xICgyRN5qvx?usp=sharing


---

## âš™ï¸ Installation

```bash
pip install -r requirements.txt
ğŸ§¨ Running NEPI Attack Evaluation
python scripts/run_attack_eval.py
This produces:

Attack Success Rate (ASR) results

Model-wise breakdown

Output logs for analysis

ğŸ›¡ï¸ Running Defense Evaluation
python scripts/run_defense_eval.py
This produces:

ASR reduction metrics

False positive rates

Runtime overhead measurements

ğŸ“ˆ Generating Figures
python scripts/generate_figures.py
This generates:

Heatmaps

Bar plots

ROC / PR curves

Scatter tradeoff plots

ğŸ“Œ Reproducibility
For full reproducibility details, see:

docs/REPRODUCIBILITY.md

ğŸ“– Citation
If you use this repository in your research, please cite our work.

See: CITATION.cff

ğŸ“œ License
This project is released under the MIT License (code only).
Dataset release may follow a research-oriented license.

ğŸ”— Project Links
GitHub Repository: https://github.com/Vaibhav-GOAT/NEPI-Attack-Defense
Colab Notebook: https://colab.research.google.com/drive/1zwlhjOY_ra3-USTzXeGt4xICgyRN5qvx?usp=sharing
Dataset (HuggingFace): https://huggingface.co/datasets/Vaibhav-GOAT/nepi-prompts-dataset
ğŸ‘¥ Authors
Vaibhav Pawar (NIT Jalandhar)
Dr. Urvashi (Supervisor, NIT Jalandhar)
ğŸ“¬ Contact
For collaboration or correspondence:
vaibhavpp.is.24@nitj.ac.in
vaibhavpitambarpawar69@gmail.com
